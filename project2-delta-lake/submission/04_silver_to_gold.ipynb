{"cells":[{"cell_type":"markdown","source":["# Silver to Gold - Building Aggregate Data Marts for End Users\n\nWe will now perform some aggregations on the data, as requested by one of our end users who wants to be able to quickly see summary statistics, aggregated by device id, in a dashboard in their chosen BI tool."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e8c9a0a-b1db-4b77-b4f3-91b2ce93836c"}}},{"cell_type":"markdown","source":["## Notebook Objective\n\nIn this notebook we:\n1. Create aggregations on the Silver table data\n1. Load the aggregate data into a Gold table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac830e01-33a7-4676-a21a-4c05fc5218d1"}}},{"cell_type":"markdown","source":["## Step Configuration"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d2e0e06-efb7-47c4-8de4-dc9de3a77e79"}}},{"cell_type":"code","source":["%run ./includes/configuration"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d4c8bb3-973e-42f0-8def-2e3ce76295cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[3]: DataFrame[]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[3]: DataFrame[]"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"No running streams.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["No running streams.\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Import Operation Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc882ab0-986a-4118-8ab3-f0853bba5169"}}},{"cell_type":"code","source":["%run ./includes/main/python/operations"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80229db8-9a88-49c4-a4e2-0997d4154bb6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Display the Files in the Raw Paths"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acdb26c2-a304-4f64-a5c5-6b66a6338e22"}}},{"cell_type":"code","source":["display(dbutils.fs.ls(rawPath))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd68163d-cd94-47bf-8f77-1123f0fc96d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/dbacademy/gaurav_chattree/dataengineering/plus/raw/health_tracker_data_2020_1.json","health_tracker_data_2020_1.json",310628],["dbfs:/dbacademy/gaurav_chattree/dataengineering/plus/raw/health_tracker_data_2020_2.json","health_tracker_data_2020_2.json",284670],["dbfs:/dbacademy/gaurav_chattree/dataengineering/plus/raw/late/","late/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/dbacademy/gaurav_chattree/dataengineering/plus/raw/health_tracker_data_2020_1.json</td><td>health_tracker_data_2020_1.json</td><td>310628</td></tr><tr><td>dbfs:/dbacademy/gaurav_chattree/dataengineering/plus/raw/health_tracker_data_2020_2.json</td><td>health_tracker_data_2020_2.json</td><td>284670</td></tr><tr><td>dbfs:/dbacademy/gaurav_chattree/dataengineering/plus/raw/late/</td><td>late/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Make Notebook Idempotent"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2a6f200-c7c9-410e-a6bb-079f0f504729"}}},{"cell_type":"code","source":["dbutils.fs.rm(goldPath, recurse=True)\ndbutils.fs.rm(goldCheckpoint, recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e910b9f7-2800-4aec-8ff7-5ac171f26f10"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[16]: False","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[16]: False"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Start Streams\n\nBefore we add new streams, let's start the streams we have previously engineered.\n\nWe will start two named streams:\n\n- `write_raw_to_bronze`\n- `write_bronze_to_silver`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52352213-b723-4151-a099-024e2c08ab6b"}}},{"cell_type":"markdown","source":["### Current Delta Architecture\n\nNext, we demonstrate everything we have built up to this point in our\nDelta architecture.\n\nAgain, we do so with composable functions included in the\nfile `includes/main/python/operations`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac756c57-813f-4e9c-9ba5-32abe789270c"}}},{"cell_type":"code","source":["rawDF = read_stream_raw(spark, rawPath)\ntransformedRawDF = transform_raw(rawDF)\nrawToBronzeWriter = create_stream_writer(\n    dataframe=transformedRawDF,\n    checkpoint=bronzeCheckpoint,\n    name=\"write_raw_to_bronze\",\n    partition_column=\"p_ingestdate\",\n)\nrawToBronzeWriter.start(bronzePath)\n\nbronzeDF = read_stream_delta(spark, bronzePath)\ntransformedBronzeDF = transform_bronze(bronzeDF)\nbronzeToSilverWriter = create_stream_writer(\n    dataframe=transformedBronzeDF,\n    checkpoint=silverCheckpoint,\n    name=\"write_bronze_to_silver\",\n    partition_column=\"p_eventdate\",\n)\nbronzeToSilverWriter.start(silverPath)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"388d7826-bc24-498d-9ce1-c22a898b215a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[17]: <pyspark.sql.streaming.StreamingQuery at 0x7f99a74c4dc0>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[17]: <pyspark.sql.streaming.StreamingQuery at 0x7f99a74c4dc0>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Update the Silver Table\n\nWe periodically run the `update_silver_table` function to update the table and address the known issue of negative readings being ingested."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b46c9cc3-f895-4826-a004-3608bd9ebf8d"}}},{"cell_type":"code","source":["update_silver_table(spark, silverPath)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7ce0a23-3566-4b30-812f-c5de8210b8ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[19]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[19]: True"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Show Running Streams"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f0e91fb-e3cc-4bdb-a4e2-eb004a6f948e"}}},{"cell_type":"code","source":["for stream in spark.streams.active:\n    print(stream.name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5deb470d-f347-4792-9c37-281eda3485b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"write_bronze_to_silver\nwrite_raw_to_bronze\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["write_bronze_to_silver\nwrite_raw_to_bronze\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create Aggregation per User"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"398c991d-8e6c-4cae-8850-bd00c3836ef3"}}},{"cell_type":"markdown","source":["**Exercise:** Create a read stream DataFrame and aggregate over the Silver table\n\nUse the following aggregates:\n- mean of heartrate, aliased as `mean_heartrate`\n- standard deviation of heartrate, aliased as `std_heartrate`\n- maximum of heartrate, aliased as `max_heartrate`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2e47c33-6106-4111-a52a-65dd8a9483af"}}},{"cell_type":"code","source":["# TODO\n\nfrom pyspark.sql.functions import col, mean, stddev, max\n\nsilverTableReadStream = read_stream_delta(spark, silverPath)\n\ngold_health_tracker_data_df =(\n    silverTableReadStream.groupBy(\"device_id\")\n    .agg(\n    mean(col(\"heartrate\")).alias(\"mean_heartrate\"),\n    stddev(col(\"heartrate\")).alias(\"std_heartrate\"),\n    max(col(\"heartrate\")).alias(\"max_heartrate\"),\n  )\n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49012e4a-a086-4287-8f4b-965d28c3a4e3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## WRITE Stream Gold Table Aggregation\n\nNote that we cannot use outputMode \"append\" for aggregations - we have to use \"complete\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3889f89-4f43-4b26-aa04-ced020cfcb40"}}},{"cell_type":"markdown","source":["**Exercise:** Write the aggregate DataFrame to a Gold table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c05aab4-7030-4985-9060-ee6664ee8f7e"}}},{"cell_type":"code","source":["\ntableName = \"aggregate_heartrate\"\ntableCheckpoint = goldCheckpoint + tableName\ntablePath = goldPath + tableName\n\n(\n  gold_health_tracker_data_df.writeStream\n  .format(\"delta\")\n  .outputMode(\"complete\")\n  .option(\"checkpointLocation\", tableCheckpoint)\n  .queryName(\"write_silver_to_gold\")\n  .start(tablePath)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c44553f-8324-4791-9d3c-cfad2dddd985"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[23]: <pyspark.sql.streaming.StreamingQuery at 0x7f99a74c4610>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[23]: <pyspark.sql.streaming.StreamingQuery at 0x7f99a74c4610>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Register Gold Table in the Metastore"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0a3a320-7f7d-4826-8546-4f0c0a4804e8"}}},{"cell_type":"code","source":["spark.sql(\n    \"\"\"\nDROP TABLE IF EXISTS health_tracker_gold_aggregate_heartrate\n\"\"\"\n)\n\nspark.sql(\n    f\"\"\"\nCREATE TABLE health_tracker_gold_aggregate_heartrate\nUSING DELTA\nLOCATION \"{tablePath}\"\n\"\"\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aca97d32-8d3a-4955-89de-38ef6a1f1c42"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[25]: DataFrame[]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[25]: DataFrame[]"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Troubleshooting\n\n😫 If you try to run this before the `writeStream` above has been created, you may see the following error:\n\n`\nAnalysisException: Table schema is not set.  Write data into it or use CREATE TABLE to set the schema.;`\n\nIf this happens, wait a moment for the `writeStream` to instantiate and run the command again."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65945cc4-be8f-4a0d-8c9e-8e60f66bbd59"}}},{"cell_type":"markdown","source":["We could now use this `health_tracker_gold` Delta table to define a dashboard. The query used to create the table could be issued nightly to prepare the dashboard for the following business day, or as often as needed according to SLA requirements."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"608a6a43-a864-48f6-8972-7b80477ce1a8"}}},{"cell_type":"markdown","source":["## Stop All Streams\n\nIn the next notebook, you will harden the Silver to Gold Step.\n\nBefore we do so, let's shut down all streams in this notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0dd635a9-0935-48c4-9877-701c4825bb25"}}},{"cell_type":"code","source":["stop_all_streams()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b349c4f-d2a4-437e-a209-8f79b32046bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[26]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[26]: True"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34731417-5a75-4a4e-be2f-848403142230"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"04_silver_to_gold","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3719025789002020}},"nbformat":4,"nbformat_minor":0}
